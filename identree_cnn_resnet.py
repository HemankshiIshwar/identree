# -*- coding: utf-8 -*-
"""identree_cnn_resnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RwX3dTnkVbvSMsDexFIC7wBBW8LiLnFa

Import Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""Import Libraries"""

# Standard Libraries
import os
import random
import json

# Data Manipulation and Preprocessing
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator
from keras.applications.vgg16 import preprocess_input
from sklearn.model_selection import train_test_split
from keras.layers.reshaping.reshape import Reshape

# Deep Learning Frameworks and Tools
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout
from keras.optimizers import Adam
from keras.initializers import HeNormal
from keras.regularizers import l2
from tensorflow.keras import models
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import EarlyStopping

# Data Visualization and Evaluation
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


from tensorflow.keras.models import load_model
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model

import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.applications import ResNet50

# Load and preprocess images, and create labels dynamically
image_size = (224, 224)
image_paths = []
labels = []

# Function to load and preprocess images
def load_and_preprocess_image(image_path):
    try:
        # Load image
        img = load_img(image_path, target_size=image_size)

        # Convert to array
        img_array = img_to_array(img)

        # Calculate mean for each channel
        channel_means = np.mean(img_array, axis=(0, 1))

        # Subtract the channel means from the respective channels
        img_array_zero_centered = img_array - channel_means #Zero-centering

        # Calculate standard deviation for each channel
        channel_stds = np.std(img_array_zero_centered, axis=(0, 1))

        # Divide the zero-centered image data by the channel standard deviations
        img_array_normalized = img_array_zero_centered / channel_stds  #Normalization

        img_array = preprocess_input(img_array) # It performs Mean Subtraction(Zero centering), Normalization, Channel Ordering, Image Resizing, Pixel Value Scaling and Data Format conversion
        return img_array

    except Exception as e:
        print(f"Error loading image: {image_path}, Error: {e}")
        return None

# Path to the main data directory
data_dir = "/content/drive/MyDrive/Identree/Data/flavia"

# Get list of subdirectories (class names)
class_names = os.listdir(data_dir)

# Initialize dictionaries to store class information
class_info = {}

for class_idx, class_name in enumerate(class_names):
    class_info[class_idx] = class_name
    class_dir = os.path.join(data_dir, class_name)
    class_image_paths = [os.path.join(class_dir, img_name) for img_name in os.listdir(class_dir) if img_name.lower().endswith(('.jpg', '.jpeg'))]
    image_paths.extend(class_image_paths)
    labels.extend([class_idx] * len(class_image_paths))

# Save the class information to a JSON file
json_filename = 'class_info.json'
with open(json_filename, 'w') as json_file:
    json.dump(class_info, json_file, indent=4)

print("Class information filename", json_filename)

# Load and preprocess images
images = [load_and_preprocess_image(img_path) for img_path in image_paths]
images = [img for img in images if img is not None]

# Convert the data to numpy arrays
X = np.array(images)
y = np.array(labels)

# Split the data into training, validation, and testing sets
# Split into training and temp (combined validation and testing)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)

# Split the temp set into validation and testing
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""Fine tuning cnn model with data augmentation"""

# Define hyperparameters
input_shape = (224, 224, 3)
num_classes = len(class_names)
activation = 'relu'
num_filters = 32
filter_size = (5, 5)
pool_size = (2, 2)
dense_units = 256
num_epochs = 40
batch_size = 48
dropout_rate = 0.5
learning_rate = 1e-4
adam_optimizer = Adam(learning_rate=learning_rate)

# Define data augmentation parameters
datagen = ImageDataGenerator(
    rotation_range=0.5,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=False,
    zoom_range=0.1
)

# Create an EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Create data generators with data augmentation
train_datagen = datagen.flow(X_train, y_train, batch_size=batch_size)
val_datagen = datagen.flow(X_val, y_val, batch_size=batch_size)

# Load a pre-trained ResNet model without top layers
resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)

# Combine the ResNet base and custom CNN
x = GlobalAveragePooling2D()(resnet_base.output)
# Add a Reshape layer to reshape the output
x = Reshape((1, 1, 2048))(x)
# Flatten the output
x = Flatten()(x)
# Add custom dense layers
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(num_classes, activation='softmax')(x)


# Create the combined model
model = Model(inputs=resnet_base.input, outputs=x)

# Compile the combined model
model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])

# Train the model with the specified number of epochs
history = model.fit(train_datagen, epochs=num_epochs, batch_size=batch_size, validation_data=val_datagen, callbacks=[early_stopping])

# Create lists to store training history
training_loss = []
training_accuracy = []
validation_loss = []
validation_accuracy = []

# Record training and validation loss and accuracy
training_loss = history.history['loss']
training_accuracy = history.history['accuracy']
validation_loss = history.history['val_loss']
validation_accuracy = history.history['val_accuracy']

# Plot the accuracy curves
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 2)
plt.plot(training_accuracy, label='Training Accuracy')
plt.plot(validation_accuracy, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot the loss curves
plt.subplot(1, 2, 1)
plt.plot(training_loss, label='Training Loss')
plt.plot(validation_loss, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()

# Calculate and print the average training and validation accuracy and loss
avg_training_accuracy = sum(training_accuracy) / num_epochs
avg_validation_accuracy = sum(validation_accuracy) / num_epochs
avg_training_loss = sum(training_loss)/ num_epochs
avg_validation_loss = sum(validation_loss) / num_epochs

print(f"Average Training Accuracy: {avg_training_accuracy:.4f}")
print(f"Average Validation Accuracy: {avg_validation_accuracy:.4f}")
print(f"Average Training Loss: {avg_training_loss:.4f}")
print(f"Average Validation Loss: {avg_validation_loss:.4f}")

# Save the model
model.save("/content/drive/MyDrive/Identree/Model/identree_model_cnn_resnet.h5")

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print("Test Accuracy:", accuracy)

# Plot the model architecture
plot_model(model, to_file="/content/drive/MyDrive/Identree/Model/identree_model_cnn_resnet_architecture.png", show_shapes=True)

# Make predictions on the test set
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

print("Classification Report:")
print(classification_report(y_test, y_pred))

print("Confusion Matrix:")
# print(confusion_matrix(y_test, y_pred))
confusion_matrix_cnn = confusion_matrix(y_test, y_pred)
# Plot the confusion matrix as a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_cnn, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

weights = []
layer_names = []

for layer in model.layers:
    if len(layer.get_weights()) > 0:
        weights.append(layer.get_weights()[0].flatten())
        layer_names.append(layer.name)

# Plot histograms of the weights with layer names
plt.figure(figsize=(50, 30))
for i, (w, name) in enumerate(zip(weights, layer_names)):
    plt.subplot(1, len(weights), i + 1)
    plt.hist(w, bins=50)
    plt.title(f'{name} Weights')
    plt.xlabel('Weight Value')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Choose a random image index
random_image_idx = np.random.randint(0, len(image_paths))
random_image_path = image_paths[random_image_idx]
random_image = load_and_preprocess_image(random_image_path)

# Extract intermediate layer outputs for visualization
layer_outputs = [layer.output for layer in model.layers[1:6]]
activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(random_image[np.newaxis, ...])

# Display activation distribution histograms in a single row
num_layers = len(activations)

plt.figure(figsize=(16, 4))

for layer_index, (layer_activation, layer) in enumerate(zip(activations, activation_model.layers), 1):
    num_filters = layer_activation.shape[-1]

    # Create a subplot for the activation distribution
    plt.subplot(1, num_layers, layer_index)
    plt.hist(layer_activation.ravel(), bins=50)
    plt.title(f'Layer {layer_index} Activation Distribution')
    plt.xlabel('Activation Value')
    plt.ylabel('Frequency')

    # Print the size (shape) of the layer
    print(f"Layer {layer_index} - {layer.name} - Output Shape: {layer_activation.shape}")

plt.tight_layout()
plt.show()

# Choose a random image index
random_image_idx = np.random.randint(0, len(image_paths))
random_image_path = image_paths[random_image_idx]
random_image = load_and_preprocess_image(random_image_path)

# Show the original image
plt.figure(figsize=(4, 4))
plt.imshow(array_to_img(random_image))
plt.title("Original Image")

# Extract intermediate layer outputs for visualization
layer_outputs = [layer.output for layer in model.layers[1:6]]
activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(random_image[np.newaxis, ...])

# Display activations at different layers
for layer_activation in activations:
    num_filters = layer_activation.shape[-1]
    plt.figure(figsize=(num_filters, 1))
    for i in range(num_filters):
        plt.subplot(1, num_filters, i+1)
        plt.imshow(layer_activation[0, :, :, i], cmap='viridis')
        plt.axis('off')

plt.show()